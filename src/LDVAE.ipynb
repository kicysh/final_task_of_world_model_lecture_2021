{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDVAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcehvvUcvIBFLMiv0XNrpS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kicysh/final_task_of_world_model_lecture_2021/blob/main/src/LDVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pip"
      ],
      "metadata": {
        "id": "mF-ceB4dTt1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy"
      ],
      "metadata": {
        "id": "r2EsievTT474"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "kZnO-gmJTTwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!gsutil cp gs://h5ad/2019-02-Pijuan-Sala-et-al-Nature/pijuan_sala_atlas.h5ad /content/data\n",
        "path_of_data = '/content/data/pijuan_sala_atlas.h5ad'\n"
      ],
      "metadata": {
        "id": "GCBTOxD6Tg7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setting\n"
      ],
      "metadata": {
        "id": "47p9z8QQs4bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting\n",
        "SETTING_BATCHNORM_EPS = 0.001\n",
        "SETTING_BATCHNORM_MOMENTUM = 0.01\n",
        "SETTING_ENCODER_Z_DROPOUT_P = 0.1\n",
        "SETTING_ENCODER_L_DROPOUT_P = 0.1\n",
        "SETTING_HIDDEN_DIM = 128\n",
        "SETTING_EPS = 1e-8\n",
        "\n",
        "USE_CUDA = True"
      ],
      "metadata": {
        "id": "grS7L_2ms24J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "Q0rzv6RVs9sr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HFG8utJ7LYQm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import logsumexp\n",
        "from torch.distributions import Normal, kl_divergence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scanpy as sc\n",
        "adata = sc.read_h5ad(path_of_data)\n",
        "adata"
      ],
      "metadata": {
        "id": "1BzFALOqUJ-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from math import ldexp\n",
        "\n",
        "class LDVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    :param genes_cnt: Number of input genes\n",
        "    :param latent_dim: Dimensionality of the latent space \n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        genes_cnt: int, \n",
        "        latent_dim: int = 20\n",
        "    ):\n",
        "        super(LDVAE,self).__init__()\n",
        "        self.local_l_mean = None\n",
        "        self.local_l_std = None\n",
        "        self.eps = SETTING_EPS\n",
        "\n",
        "        self.theta = nn.Parameter(torch.randn(genes_cnt))\n",
        "        self.encoder_z = nn.Sequential(\n",
        "            nn.Linear(genes_cnt, SETTING_HIDDEN_DIM),\n",
        "            nn.BatchNorm1d(SETTING_HIDDEN_DIM,\n",
        "                           eps=SETTING_BATCHNORM_EPS, \n",
        "                           momentum=SETTING_BATCHNORM_MOMENTUM),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(SETTING_ENCODER_Z_DROPOUT_P)\n",
        "        )\n",
        "        self.encoder_z_mean = nn.Lineer(SETTING_HIDDEN_DIM,latent_dim)\n",
        "        self.encoder_z_std = nn.Lineer(SETTING_HIDDEN_DIM,latent_dim)\n",
        "\n",
        "        self.encoder_l = nn.Sequential(\n",
        "            nn.Linear(genes_cnt, SETTING_HIDDEN_DIM),\n",
        "            nn.BatchNorm1d(SETTING_HIDDEN_DIM,\n",
        "                           eps=SETTING_BATCHNORM_EPS, \n",
        "                           momentum=SETTING_BATCHNORM_MOMENTUM),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(SETTING_ENCODER_L_DROPOUT_P)\n",
        "        )\n",
        "        self.encoder_l_mean = nn.Lineer(SETTING_HIDDEN_DIM, 1)\n",
        "        self.encoder_l_std = nn.Lineer(SETTING_HIDDEN_DIM, 1)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, genes_cnt),\n",
        "            nn.BatchNorm1d(genes_cnt,\n",
        "                           eps=SETTING_BATCHNORM_EPS, \n",
        "                           momentum=SETTING_BATCHNORM_MOMENTUM)\n",
        "        )\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x_z = self.encoder_z(x)\n",
        "        z_mean = self.encoder_z_mean(x_z)\n",
        "        z_std = self.encoder_z_std(x_z)\n",
        "        z = Normal(z_mean, z_std.sqrt()).rsample()\n",
        "\n",
        "        x_l = self.encoder_l(x)\n",
        "        l_mean = self.encoder_l_mean(x_l)\n",
        "        l_std = self.encoder_l_std(x_l)\n",
        "        library = Normal(l_mean, l_std.sqrt()).rsample()\n",
        "\n",
        "        y = self.decoder(z)\n",
        "        y = torch.exp(library)*torch.softmax(y, dim=-1)\n",
        "        return [z_mean, z_std, z], [l_mean, l_std, library], y\n",
        "\n",
        "    def set_local_l_mean_and_std(self, data):\n",
        "        masked_log_sum =np.ma.log(data.sum(axis=1))\n",
        "        log_counts = masked_log_sum.filled(0)\n",
        "        self.local_mean = (np.mean(log_counts).reshape(-1, 1)).astype(np.float32)\n",
        "        self.local_var = (np.var(log_counts).reshape(-1, 1)).astype(np.float32)\n",
        "        return self.local_mean, self.local_var\n",
        "\n",
        "    def reconst_error(self,x, mu, theta):\n",
        "        eps = SETTING_EPS\n",
        "        log_theta_mu_eps = torch.log(theta + mu + eps)\n",
        "\n",
        "        res = (\n",
        "            theta * (torch.log(theta + eps) - log_theta_mu_eps)\n",
        "            + x * (torch.log(mu + eps) - log_theta_mu_eps)\n",
        "            + torch.lgamma(x + theta)\n",
        "            - torch.lgamma(theta)\n",
        "            - torch.lgamma(x + 1)\n",
        "        )\n",
        "\n",
        "    return res\n",
        "\n",
        "    def loss(self,x):\n",
        "        zs,ls,y = self.forward(x)\n",
        "        z_mean, z_std, z = zs\n",
        "        l_mean, l_std, library = ls\n",
        "\n",
        "        mean, std = torch.zeros_like(z_mean), torch.ones_like(z_std)\n",
        "        kl_z = kl_divergence(Normal(z_mean,torch.sqrt(z_std)), Normal(mean, std)).sum(dim=1)\n",
        "\n",
        "        mean, std = self.local_l_mean, self.local_l_std\n",
        "        kl_l = kl_divergence(Normal(l_mean,torch.sqrt(l_std)), Normal(mean, torch.sqrt(std))).sum(dim=1)\n",
        "\n",
        "        reconst = self.reconst_error(x, mu=y, theta=torch.exp(self.theta)).sum(dim=-1)\n",
        "        \n",
        "        return reconst, kl_l ,kl_z"
      ],
      "metadata": {
        "id": "xWIBSs3AtBUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LDVAE(genes_cnt = adata.n_vars,\n",
        "              latent_dim = 20)\n",
        "model"
      ],
      "metadata": {
        "id": "Usgub80pSxzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloder"
      ],
      "metadata": {
        "id": "zHMDdp6BY4yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "n_epochs  = 10\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0002,  betas=(0.5,0.999))\n",
        "\n",
        "deice = 'cuda'  if USE_CUDA else 'cpu'\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    losses = []\n",
        "\n",
        "    model.train()\n",
        "    for x, _ in dataloader_train:\n",
        "        x = x.to(device)\n",
        "        x = x.view(-1,1,28,28)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # forawrd and loss\n",
        "        reconst, kl_l ,kl_z = model.loss(x)\n",
        "        loss = torch.mean(reconst+kl_l +kl_z)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "\n",
        "    losses_val1 = []\n",
        "    losses_val2 = []\n",
        "    losses_val3 = []\n",
        "    model.eval()\n",
        "    for x, t in dataloader_valid:\n",
        "\n",
        "        x = x.to(device)\n",
        "        x = x.view(-1,1,28,28)\n",
        "\n",
        "\n",
        "        reconst, kl_l ,kl_z = model.loss(x)\n",
        "\n",
        "        losses_val1.append(torch.mean(reconst).cpu().detach().numpy())\n",
        "        losses_val2.append(torch.mean(kl_l).cpu().detach().numpy())\n",
        "        losses_val3.append(torch.mean(kl_z).cpu().detach().numpy())\n",
        "\n",
        "    print('EPOCH: %d    Train Loss: %lf    Valid rec: %lf    Valid kl_l: %lf    Valid kl_z: %lf' %\n",
        "            (epoch+1, np.average(losses),np.average(losses_val1),np.average(losses_val2),np.average(losses_val3)))\n"
      ],
      "metadata": {
        "id": "tX4KoKFiWQxs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}